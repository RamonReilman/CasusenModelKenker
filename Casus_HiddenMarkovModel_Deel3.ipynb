{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://bioinf.nl/~davelangers/hanze.png\" align=\"right\" />\n",
    "\n",
    "# <span id=\"0\">Casus *Hidden Markov Model* - Deel III</span>\n",
    "\n",
    "Inhoud:\n",
    "\n",
    "* **<a href=\"#1\">Het Viterbi algoritme</a>**\n",
    "\n",
    "* **<a href=\"#2\">Het decoding probleem</a>**\n",
    "\n",
    "* **<a href=\"#3\">Rekenvoorbeeld</a>**\n",
    "\n",
    "* **<a href=\"#4\">Je eigen `HiddenMarkovModel` class</a>**\n",
    "\n",
    "* **<a href=\"#5\">CpG-eilandjes</a>**"
   ],
   "id": "d59dc04fc50d627e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "a207e279629977c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"1\" href=\"#0\" style=\"text-align: right; display: block;\">Terug naar boven</a>\n",
    "\n",
    "### Het Viterbi algoritme\n",
    "\n",
    "Het Viterbi-algoritme is een [dynamisch](https://en.wikipedia.org/wiki/Dynamic_programming) programmeeralgoritme voor het verkrijgen van de meest waarschijnlijke reeks verborgen toestanden die resulteert in een reeks waargenomen gebeurtenissen. Dit gebeurt vooral in de context van Hidden Markov modellen, maar er zijn ook andere toepassingen.\n",
    "\n",
    "Bekijk onderstaande inleidende video waarin het algoritme wordt gebruikt om de kortste route tussen twee bestemmingen te bepalen. Het voordeel van het Viterby-algoritme is dat je niet alle mogelijke routes hoeft op te sommen; tijdens de toepassing van het algoritme vallen vele mogelijk routes die niet optimaal kunnen zijn vanzelf al af, en deze hoef je daardoor niet helemaal door te rekenen."
   ],
   "id": "e1e5452cd98aeeaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%html\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/6JVqutwtzmo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ],
   "id": "492b55244fdfaff5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In het onderstaande kaartje staan afstanden (in km) aangegeven om in zes (verschillend gekleurde) stappen van Groningen naar zuid-Nederland te reizen. Gebruik het Viterbi-algoritme om de kortste afstand vanuit Groningen naar elke stad in dit kaartje te bepalen, vergelijkbaar met wat er in de video gedaan wordt. Je mag alleen de richting van de pijlen volgen. Geef als eindresultaat de afstanden van Groningen tot Middelburg, Breda, Tilburg, Eindhoven en Maastricht, plus de paden die je volgt om vanuit Groningen optimaal in die steden terecht te komen.\n",
    "\n",
    "![Casus_HiddenMarkovModel_Deel3_kaartje.jpg](attachment:Casus_HiddenMarkovModel_Deel3_kaartje.jpg)\n",
    "\n",
    "[Image credit](https://depositphotos.com/nl/vector/political-map-netherlands-national-borders-cities-rivers-646536752.html)"
   ],
   "id": "1f928a6a4e5222ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# UITWERKING",
   "id": "94d596bc9d523411"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"2\" href=\"#0\" style=\"text-align: right; display: block;\">Terug naar boven</a>\n",
    "\n",
    "### Het decoding probleem\n",
    "\n",
    "In een vorige les heb je een reeks knikkers getrokken aan drie verschillende tafels. De gegevens omtrent overgangswaarschijnlijkheden en emissiekansen kun je aflezen uit de inmiddels bekende gegevens omtrent de opzet van het experiment:\n",
    "\n",
    "| Tafel: |  ❶  |  ❷  |  ❸  |\n",
    "| -----: | :-: | :-: | :-: |\n",
    "| **Grabbelton:** | 6x blauw | 2x blauw | 1x blauw |\n",
    "|                 | 3x geel  | 6x geel  | 0x geel  | \n",
    "|                 | 1x groen | 2x groen | 6x groen |\n",
    "|                 | 2x rood  | 2x rood  | 5x rood  |\n",
    "| **Dobbelsteen:** | ⚀→① | ⚀→① | ⚀→① |\n",
    "|                  | ⚁→② | ⚁→② | ⚁→① |\n",
    "|                  | ⚂→② | ⚂→② | ⚂→① |\n",
    "|                  | ⚃→② | ⚃→③ | ⚃→① |\n",
    "|                  | ⚄→③ | ⚄→③ | ⚄→② |\n",
    "|                  | ⚅→③ | ⚅→③ | ⚅→③ |\n",
    "\n",
    "In de praktijk van Hidden Markov Models hebben we waarnemingen (kleuren knikkers) maar kennen we niet de toestanden (de tafels). Laten we eens proberen te berekenen wat de *meest waarschijnlijke* reeks tafels is die ten grondslag ligt aan de volgende reeks gekleurde knikkers:\n",
    "\n",
    "| **Beurt:** | 1     | 2     | 3     | 4     | 5     |\n",
    "| ---------: | :---: | :---: | :---: | :---: | :---: |\n",
    "| **Kleur:** | geel  | groen | blauw | rood  | groen |\n",
    "\n",
    "We noemen dit het *decoding-probleem*. Hiervoor kunnen we het Viterby-algoritme gebruiken. In dit geval *minimaliseren* we niet de totale *afstand* tussen steden, maar *maximaliseren* we de *kans* op emissies en toestanden. In plaats van bij te houden via welke *steden* je zou moeten reizen houden we bij via welke *toestanden* de uitkomsten het meest waarschijnlijk zijn.\n",
    "\n",
    "Het Viterbi-algoritme begint met alleen het begin van de reeks te beschouwen: eerst kijken we alleen naar beurt 1.\n",
    "\n",
    "##### Beurt 1\n",
    "\n",
    "In beurt 1 werd een gele knikker getrokken. Er zijn drie manieren hoe dit zou kunnen geschieden:\n",
    "\n",
    "* Vanuit tafel ❶:<br />de kans dat je begint aan tafel ❶ is $\\frac{1}{3}$, en de kans dat je daar een gele knikker trekt is $\\frac{3}{12} = \\frac{1}{4}$, dus de kans dat je via tafel ❶ een gele knikker trekt is\n",
    "\n",
    "$$\n",
    "P(❶_1 \\cap \\text{geel}_1) = \\frac{1}{3} \\cdot \\frac{1}{4} = \\frac{1}{12}\n",
    "$$\n",
    "\n",
    "* Vanuit tafel ❷:<br />de kans dat je begint aan tafel ❷ is $\\frac{1}{3}$, en de kans dat je daar een gele knikker trekt is $\\frac{6}{12} = \\frac{1}{2}$, dus de kans dat je via tafel ❷ een gele knikker trekt is\n",
    "\n",
    "$$\n",
    "P(❷_1 \\cap \\text{geel}_1) = \\frac{1}{3} \\cdot \\frac{1}{2} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "* Vanuit tafel ❸:<br />de kans dat je begint aan tafel ❸ is $\\frac{1}{3}$, en de kans dat je daar een gele knikker trekt is $\\frac{0}{12} = 0$, dus de kans dat je via tafel ❸ een gele knikker trekt is\n",
    "\n",
    "$$\n",
    "P(❸_1 \\cap \\text{geel}_1) = \\frac{1}{3} \\cdot 0 = 0\n",
    "$$\n",
    "\n",
    "We kunnen dit samenvatten in een tabel:\n",
    "\n",
    "| **Beurt:** | 1     |\n",
    "| ---------: | :---: |\n",
    "|            | p = $\\frac{1}{12}$ via ❶ |\n",
    "|            | p = $\\frac{1}{6}$ via ❷ |\n",
    "|            | p = $0$ via ❸ |\n",
    "\n",
    "Het meest waarschijnlijk, tot dusverre, is dat de toestand behorende bij beurt 1 overeenkomt met tafel ❷, want dat heeft de hoogste kans.\n",
    "\n",
    "##### Beurt 2\n",
    "\n",
    "In beurt 2 werd een groene knikker getrokken. Er zijn drie manieren hoe dit zou kunnen geschieden:\n",
    "\n",
    "* Vanuit tafel ❶:<br />Je kan op drie manieren aan tafel ❶ terechtkomen in beurt 2:\n",
    "  * als je aan tafel ❶ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❶ was $\\frac{1}{12}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❶ met een dobbelsteenworp naar tafel ❶ gaat is $\\frac{1}{6}$;\n",
    "    * de kans dat je vanuit tafel ❶ een groene knikker trekt is $\\frac{1}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❶ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $\\frac{1}{12} \\cdot \\frac{1}{6} \\cdot \\frac{1}{12} = \\frac{1}{864} \\approx 0.00116$\n",
    "  * als je aan tafel ❷ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❷ was $\\frac{1}{6}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❷ met een dobbelsteenworp naar tafel ❶ gaat is $\\frac{1}{6}$;\n",
    "    * de kans dat je vanuit tafel ❶ een groene knikker trekt is $\\frac{1}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❷ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $\\frac{1}{6} \\cdot \\frac{1}{6} \\cdot \\frac{1}{12} = \\frac{1}{432} \\approx 0.00231$\n",
    "  * als je aan tafel ❸ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❸ was $0$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❸ met een dobbelsteenworp naar tafel ❶ gaat is $\\frac{4}{6}$;\n",
    "    * de kans dat je vanuit tafel ❶ een groene knikker trekt is $\\frac{1}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❷ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $0 \\cdot \\frac{4}{6} \\cdot \\frac{1}{12} = 0 = 0.00000$\n",
    "\n",
    "De *meest waarschijnlijke* manier om in beurt 2 aan tafel ❶ te komen is dus via tafel ❷ in beurt 1, met kans\n",
    "\n",
    "$$\n",
    "P(❷_1 \\cap \\text{geel}_1 \\cap ❶_2 \\cap \\text{groen}_2) = 0.00231\n",
    "$$\n",
    "\n",
    "* Vanuit tafel ❷:<br />Je kan op drie manieren aan tafel ❷ terechtkomen in beurt 2:\n",
    "  * als je aan tafel ❶ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❶ was $\\frac{1}{12}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❶ met een dobbelsteenworp naar tafel ❷ gaat is $\\frac{3}{6}$;\n",
    "    * de kans dat je vanuit tafel ❷ een groene knikker trekt is $\\frac{2}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❶ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $\\frac{1}{12} \\cdot \\frac{3}{6} \\cdot \\frac{2}{12} = \\frac{1}{144} \\approx 0.00694$\n",
    "  * als je aan tafel ❷ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❷ was $\\frac{1}{6}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❷ met een dobbelsteenworp naar tafel ❷ gaat is $\\frac{2}{6}$;\n",
    "    * de kans dat je vanuit tafel ❷ een groene knikker trekt is $\\frac{2}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❷ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $\\frac{1}{6} \\cdot \\frac{2}{6} \\cdot \\frac{2}{12} = \\frac{1}{108} \\approx 0.00926$\n",
    "  * als je aan tafel ❸ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❸ was $0$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❸ met een dobbelsteenworp naar tafel ❷ gaat is $\\frac{1}{6}$;\n",
    "    * de kans dat je vanuit tafel ❷ een groene knikker trekt is $\\frac{2}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❸ in beurt 1 naar tafel ❶ in beurt 2 een groene knikker trekt is $0 \\cdot \\frac{1}{6} \\cdot \\frac{2}{12} = 0 = 0.00000$\n",
    "\n",
    "De *meest waarschijnlijke* manier om in beurt 2 aan tafel ❷ te komen is dus via tafel ❷ in beurt 1, met kans\n",
    "\n",
    "$$\n",
    "P(❷_1 \\cap \\text{geel}_1 \\cap ❷_2 \\cap \\text{groen}_2) = 0.00926\n",
    "$$\n",
    "\n",
    "* Vanuit tafel ❸:<br />Je kan op drie manieren aan tafel ❸ terechtkomen in beurt 2:\n",
    "  * als je aan tafel ❶ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❶ was $\\frac{1}{12}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❶ met een dobbelsteenworp naar tafel ❸ gaat is $\\frac{2}{6}$;\n",
    "    * de kans dat je vanuit tafel ❸ een groene knikker trekt is $\\frac{6}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❶ in beurt 1 naar tafel ❸ in beurt 2 een groene knikker trekt is $\\frac{1}{12} \\cdot \\frac{2}{6} \\cdot \\frac{6}{12} = \\frac{1}{72} \\approx 0.01389$\n",
    "  * als je aan tafel ❷ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❷ was $\\frac{1}{6}$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❷ met een dobbelsteenworp naar tafel ❸ gaat is $\\frac{3}{6}$;\n",
    "    * de kans dat je vanuit tafel ❸ een groene knikker trekt is $\\frac{6}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❷ in beurt 1 naar tafel ❸ in beurt 2 een groene knikker trekt is $\\frac{1}{6} \\cdot \\frac{3}{6} \\cdot \\frac{6}{12} = \\frac{1}{24} \\approx 0.04167$\n",
    "  * als je aan tafel ❸ zat in beurt 1.\n",
    "    * de kans in beurt 1 met een gele waarneming op tafel ❸ was $0$ (zie de vorige stap);\n",
    "    * de kans dat je vanaf tafel ❸ met een dobbelsteenworp naar tafel ❸ gaat is $\\frac{1}{6}$;\n",
    "    * de kans dat je vanuit tafel ❸ een groene knikker trekt is $\\frac{6}{12}$\n",
    "    <br />Dus de gecombineerde kans dat je vanaf tafel ❸ in beurt 1 naar tafel ❸ in beurt 2 een groene knikker trekt is $0 \\cdot \\frac{1}{6} \\cdot \\frac{6}{12} = 0 = 0.00000$\n",
    "\n",
    "De *meest waarschijnlijke* manier om in beurt 2 aan tafel ❸ te komen is dus via tafel ❷ in beurt 1, met kans\n",
    "\n",
    "$$\n",
    "P(❷_1 \\cap \\text{geel}_1 \\cap ❸_2 \\cap \\text{groen}_2) = 0.04167\n",
    "$$\n",
    "\n",
    "Als we nu alles tezamen bekijken, is de meest waarschijnlijke toestand in beurt 2 tafel ❸ geweest, volgend op tafel ❷ in beurt 1. Dat gaf immers een kans van 0.04167, wat hoger is dan beide andere.\n",
    "\n",
    "We breiden hiermee de tabel uit:\n",
    "\n",
    "| **Beurt:** | 1     | 2     |\n",
    "| ---------: | :---: | :---: |\n",
    "|            | p = $\\frac{1}{12}$ via ❶ | p = 0.00231 via ❷-❶ |\n",
    "|            | p = $\\frac{1}{6}$ via ❷ | p = 0.00926 via ❷-❷ |\n",
    "|            | p = $0$ via ❸ | p = 0.04167 via ❷-❸ |\n",
    "\n",
    "##### Enzovoorts\n",
    "\n",
    "We voeren steeds hetzelfde recept uit. Voor elke mogelijke tafel in de huidige beurt, beschouw elke mogelijke tafel uit de vorige beurt. Vermenigvuldig de kans die je uit die vorige beurt voor die tafel berekend had met de kans om van de vorige naar de huidige tafel over te gaan, en met de kans om dan de huidige kleur knikker te trekken. De meeste waarschijnlijke mogelijkheid \"wint\".\n",
    "\n",
    "Ga na dat je de volgende resultaten krijgt:\n",
    "\n",
    "| **Beurt:** | 1     | 2     | 3     | 4     | 5     |\n",
    "| ---------: | :---: | :---: | :---: | :---: | :---: |\n",
    "|            | p = $\\frac{1}{12}$ via ❶ | p = 0.00231 via ❷-❶ | p = 0.01389 via ❷-❸-❶ | p = 0.00039 via ❷-❸-❶-❶ | p = 0.00011 via ❷-❸-❶-❸-❶ |\n",
    "|            | p = $\\frac{1}{6}$ via ❷ | p = 0.00926 via ❷-❷ | p = 0.00116 via ❷-❸-❷ | p = 0.00116 via ❷-❸-❶-❷ | p = 0.00006 via ❷-❸-❶-❷-❷ |\n",
    "|            | p = $0$ via ❸ | p = 0.04167 via ❷-❸ | p = 0.00058 via ❷-❸-❸ | p = 0.00193 via ❷-❸-❶-❸ | p = 0.00029 via ❷-❸-❶-❷-❸ |\n",
    "\n",
    "De eindconclusie lezen we nu af in de laatste kolom: de emissies geel-groen-blauw-rood-groen zijn het meest waarschijnlijk gekomen vanuit toestanden ❷-❸-❶-❷-❸!\n",
    "\n",
    "Merk op dat er iets bijzonders kan gebeuren: in beurt vier was de meest waarschijnlijke reeks toestanden ❷-❸-❶-❸ (met een kans 0.00193), en leek het er dus op dat je in beurt vier aan tafel ❸ zat. Echter, uiteindelijk bleek de meest waarschijnlijke reeks ❷-❸-❶-❷-❸ (met kans 0.00029), en zat je in beurt vier dus aan tafel ❷. Dat wil zeggen, latere informatie heeft invloed op de beste oplossing voor eerdere beurten.\n",
    "\n",
    "De vorige les berekenden we de kans dat je exact dezelfde reeks \"geel, groen, blauw, rood, groen\" zou vinden als je achtereenvolgens de tafels ❷-❸-❶-❸-❷ zou bezoeken. We vonden toen een kans $p = 0.000054$. Nu zien we hierboven dat het VIterbi algoritme een *andere* reeks tafels produceert: ❷-❸-❶-❷-❸. Hiervoor vinden we echter een kans $p = 0.00029$. Inderdaad is die kans hoger, dus is het waarschijnlijker dat de observaties afkomstig zijn van deze reeks als je niet weet van welke tafels ze daadwerkelijk komen. Merk ook op dat de meest waarschijnlijke reeks tafels toch behoorlijk wat overlap heeft met de werkelijke reeks tafels die we niet kenden. Het Viterbi algoritme produceert dus best een redelijke schatting omtrent wat de verborgen toestanden geweest zouden zijn.\n",
    "\n",
    "Bepaal nu voor de eerste vijf beurten uit jouw eigen experimentele waarnemingen wat de meest waarschijnlijke bijbehorende serie tafels is. Is dit dezelfde reeks als de tafels die je daadwerkelijk bezocht hebt?"
   ],
   "id": "9308afaab9f81fb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|       | 1                                                                                      | 2                                                                                  | 3                                                                                            | Meest waarchijnlijk  |\n",
    "|:-----:|----------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|----------------------|\n",
    "|  geel | p=1/3*1/4= 1/12                                                                        | p=1/3*1/2= 1/6                                                                     | p=1/3*0= 0                                                                                   | tafel 2              |\n",
    "| groen | p= 1/12 *1/6 * 1/12= 1/864  p= 1/6 *1/6 * 1/12 = 1/432 ! p= 0 *2/3 * 1/12= 0           | p= 1/12 *1/2 * 1/6 1/144 p= 1/6 *1/3 * 1/6 = ! p = 0 * 1/6 *1/6 = 0                | p= 1/12 *1/3 * 1/2 1/72 p= 1/6 *1/2 * 1/2 = 1/24! p = 0 * 1/6 *1/2 = 0                       | tafel 2-3            |\n",
    "|  geel | p= 1/432*1/6 * 1/4 = 1/10368 p= 1/108 *1/6 * 1/4 = 1/2592 p = 1/24* 2/3 *1/4 = 1/144 ! | p= 1/432*1/2 * 1/2= 1/1728 p= 1/108 *1/3 * 1/2 = 1/648 p = 1/24* 1/6 *1/2 = 1/288! | p = 0 p=0 p=0                                                                                | Tafel 231            |\n",
    "| groen | p= 1/144*1/6*1/12= 1/10368! p= 1/288*1/6*1/12= 1/20736 p= 0                            | p= 1/288*1/2*1/6= 1/3456! p= 1/288*1/3*1/6= 1=5184 p= 0                            | p= 1/288*1/3*1/2= 1/1728 p= 1/288*1/2*1/2= 1/1152! p= 0                                      | Tafel 2313           |\n",
    "| blauw | p= 20736*1/6*1/2 = 1/248832 p= 3456*1/6*1/2= 1/41472 p= 1/1152*2/3*1/2= 1/3456!        | p= 1/20736*1/2*1/6=248832! p= 1/3456 *1/3*1/6= 62208 p= 1/1152* 1/6 *1/6= 41472    | p = 1/20736 *1/3*1/12=1/746496 p = 1/3456  *1/2*1/12=1/82944! p = 1/1152  *1/6*1/12=1/82944! | Tafel 23131          |\n",
    "\n"
   ],
   "id": "c0c08c982c96bb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"3\" href=\"#0\" style=\"text-align: right; display: block;\">Terug naar boven</a>\n",
    "\n",
    "### Rekenvoorbeeld\n",
    "\n",
    "De onderstaande video behandelt het decoding-probleem voor een Hidden Markov Model met twee toestanden: warm of koud weer; en drie mogelijke emissies: één, twee of drie gegeten ijsjes. (Dit voorbeeld wordt desgewenst [hier](https://www.youtube.com/watch?v=xejm-z3sbWA) nader toegelicht.) In de video wordt uitgewerkt hoe je kan nagaan wat de meest waarschijnlijke serie warme of koude dagen is geweest, gegeven dat je een aantal dagen observeert hoeveel ijsjes er gegeten worden.\n",
    "\n",
    "Bekijk de video en ga na dat je begrijpt hoe het Viterbi-algoritme in dit geval wordt toegepast om het decoding-probleem op te lossen. Als je het algoritme reeds goed denkt te begrijpen, bekijk dan de video vluchtig; als je het een ingewikkeld algoritme vindt, probeer dan daadwerkelijk elke rekenstap zelf na te doen. Als je zaken opmerkt die je noemenswaardig vindt om te onthouden, noteer die dan.\n",
    "\n",
    "Opmerking: de audio-kwaliteit en verstaanbaarheid van deze video is niet optimaal; het voorbeeld zelf is echter zeer illustratief en geschikt om door te nemen."
   ],
   "id": "7a9cec673c76b7b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%html\n",
    "<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/xejm-z3sbWA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ],
   "id": "40f364065f427b12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# UITWERKING",
   "id": "2d461a001637e1e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"4\" href=\"#0\" style=\"text-align: right; display: block;\">Terug naar boven</a>\n",
    "\n",
    "### Je eigen `HiddenMarkovModel` class\n",
    "\n",
    "Voeg nu een `predict()` methode toe aan je eigen `HiddenMarkovModel` klasse. Deze ontvangt slechts één argument: een iterable met emissies (hier de reeks kleuren; bv. `X`). De methode dient op grond van de bekende begintoestandverdeling, emissiekansen, en overgangswaarschijnlijkheden te bepalen wat de meest waarschijnlijke reeks toestanden is die overeenkomt met de gegeven emissies. Als retourwaarde wordt een iterable teruggegeven aan de gebruiker met toestanden (hier de reeks tafels; `state_sequence`). Zie de [documentatie](https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.CategoricalHMM.predict) van `hmmlearn` voor een voorbeeld van een soortgelijke API.\n",
    "\n",
    "Opnieuw geldt dat er een probleem kan ontstaan als je vele opeenvolgende waarnemingen moet doorrekenen: de kansen worden geleidelijk aan steeds kleiner, en kunnen op den duur mogelijk niet meer door een floating-point waarde gerepresenteerd worden omdat ze afgerond worden naar nul. Bij het decoding-probleem gaat het er slechts om om de toestanden met de hoogste kans te achterhalen; het berekenen van die kans deden we in het vorige deel. Daarom kun je dit numerieke afrond-probleem oplossen door alle kansen samen te schalen. Ter illustratie, in beurt 5 vonden we hierboven kansen p = 0.00011, 0.00006, en 0.00029; je zou dit kunnen opschalen naar bijvoorbeeld p = 0.11, 0.06, en 0.29. De optimale reeks toestanden verandert daardoor niet.\n",
    "\n",
    "Gebruik je eigen module om de berekening uit de voorgaande oefening voor je eerste vijf waarnemingen te controleren. Komt er hetzelfde antwoord uit? Bepaal ook de meest waarschijnlijke reeks tafels voor jouw hele eigen reeks waarnemingen. Hoeveel procent van de toestanden wordt goed voorspeld? Is dit meer dan een fractie $\\frac{1}{3}$ die je op grond van toeval zou verwachten?\n",
    "\n",
    "Gebruik de `score()` functie van je eigen module om de log-waarschijnlijkheid op de waargenomen kleuren te bepalen: vergelijk de waarschijnlijkheid op basis van de zojuist bepaalde meest waarschijnlijke reeks tafels met die op basis van de daadwerkelijke reeks tafels die je bezocht hebt. Verifieer dat de kans met de meest waarschijnlijke reeks inderdaad de hoogste is. Het kan dus zo zijn dat een andere reeks toestanden dan die welke tot de emissies leidden beter overeenkomen met de emissies!\n",
    "\n",
    "Doe hetzelfde met de waarnemingen van de klas als geheel. Hoeveel procent van de toestanden kan je Hidden Markov Model juist voorspellen? Komt dit antwoord overeen met wat `CategoricalHMM(...).predict(X)` uit de `hmmlearn` module rapporteert?"
   ],
   "id": "35ab5c3f73720b23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from hmmmodel import HiddenMarkovModel\n",
    "import numpy as np\n",
    "states = np.array([0,1,2,0,2])\n",
    "emissions = np.array([2, 1, 3, 1, 2])\n",
    "\n",
    "own_model = HiddenMarkovModel(3, 4)\n",
    "own_model.startprob_ = np.array([1/3, 1/3, 1/3])\n",
    "own_model.transmat_ = np.array([\n",
    "    [1/6, 1/2, 1/3],\n",
    "    [1/6, 1/3, 1/2],\n",
    "    [4/6, 1/6, 1/6]\n",
    "])\n",
    "# blauw, geel, groen rood\n",
    "own_model.emissionprob_ = np.array([\n",
    "    [1/2, 1/4, 1/12, 1/6],\n",
    "    [1/6, 1/2, 1/6, 1/6],\n",
    "    [1/12, 0, 1/2, 5/12]\n",
    "])"
   ],
   "id": "143fb04df2e7b236"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "emissions = np.array([3, 0, 1, 1, 2])\n",
    "own_model.newPredict(emissions)"
   ],
   "id": "a2c6a337fbea7f44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from hmmlearn.hmm import CategoricalHMM as HMM\n",
    "\n",
    "learn_model = HMM(3,4)\n",
    "learn_model.startprob_ = np.array([1/3, 1/3, 1/3])\n",
    "learn_model.transmat_ = np.array([\n",
    "    [1/6, 1/2, 1/3],\n",
    "    [1/6, 1/3, 1/2],\n",
    "    [4/6, 1/6, 1/6]\n",
    "])\n",
    "# blauw, geel, groen rood\n",
    "learn_model.emissionprob_ = np.array([\n",
    "    [1/2, 1/4, 1/12, 1/6],\n",
    "    [1/6, 1/2, 1/6, 1/6],\n",
    "    [1/12, 0, 1/2, 5/12]\n",
    "])\n"
   ],
   "id": "e25eefac0378184d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "learn_model.predict(emissions.reshape(-1,1))",
   "id": "b972b4aef4a222df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "De predictie van ons model en het learnhmmmodel zijn in deze situatie gelijk. Nu ga ik kijken of ons model dezelfde staten kan voorspellen op basis van de 1e 5 datapunten uit jasper en mijn data\n",
   "id": "d04f115ee7d49130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ramons_emissie = np.array([2, 1, 3, 1, 2])\n",
    "ramons_states = np.array([0,1,2,0,2])\n",
    "jaspers_emissie = np.array([1,2,1,2,0])\n",
    "jaspers_states = np.array([1,2,0,2,0])"
   ],
   "id": "1fccb56a34b51a05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_predicted_states(true_states, predicted_states):\n",
    "    print(f\"Predicted states: {predicted_states}\")\n",
    "    amount_equal = np.sum(predicted_states == true_states)\n",
    "    print(f\"{amount_equal} states are equal\")\n",
    "    compare = \"larger\" if (amount_equal / true_states.size) > (1/3) else \"smaller\"\n",
    "\n",
    "    print(f\"This is {compare} then the 1/3 fraction of coincidence\")"
   ],
   "id": "39c43f03bd82b257"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_states = own_model.predict(ramons_emissie)\n",
    "check_predicted_states(ramons_states, predicted_states)\n"
   ],
   "id": "d4ef9002c093aa42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_states_jasper = own_model.predict(jaspers_emissie)\n",
    "check_predicted_states(jaspers_states, predicted_states_jasper)"
   ],
   "id": "1c9c72b38ed1d96c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## data hele klas\n",
   "id": "717ad6670c478d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd",
   "id": "f73e7af8eb97e1d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv(\"./dataklass.csv\")\n",
    "data.head()"
   ],
   "id": "6a4451252a9eb442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "emissions_class = data.get(\"#emission\")\n",
    "states_class = data.get(\"#state\")"
   ],
   "id": "c4ce233741f99887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_states_class_own = own_model.predict(emissions_class.to_numpy())",
   "id": "cf048809cae31d60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_equal_own = np.sum(states_class == predicted_states_class_own)\n",
    "print(f\"{n_equal_own} predicated and true states were equal of the {states_class.size}. {n_equal_own / states_class.size * 100}%\")"
   ],
   "id": "92ef714769529baa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predicted_states_class = learn_model.predict(emissions_class.to_numpy().reshape(-1,1))",
   "id": "5fde66d4c8fb521a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_equal = np.sum(states_class == predicted_states_class)\n",
    "print(f\"{n_equal} predicated and true states were equal of the {states_class.size}. {n_equal / states_class.size * 100}%\")"
   ],
   "id": "11e030e5fe29b8b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# UITWERKING",
   "id": "3134ed24a8bc9ea8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"5\" href=\"#0\" style=\"text-align: right; display: block;\">Terug naar boven</a>\n",
    "\n",
    "### CpG-eilandjes\n",
    "\n",
    "In deel 1 genereerde je random sequenties op basis van transitiewaarschijnlijkheden zoals die voorkomen binnen en buiten CpG-eilandjes. Als we kijken naar de frequentie van verschillende nucleotiden in deze twee verschillende regio's, dan vinden we getallen zoals ongeveer hieronder:\n",
    "\n",
    "| Emissies          |   A   |   C   |   G   |   T   |\n",
    "| :---------------: | :---: | :---: | :---: | :---: |\n",
    "| **CGI** (`+`)     | 0.20  | 0.30  | 0.30  | 0.20  |\n",
    "| **non-CGI** (`-`) | 0.25  | 0.25  | 0.25  | 0.25  |\n",
    "\n",
    "CpG-eilandjes zijn gemiddeld enkele honderden base-paren lang, en worden onderling gescheiden door typisch enkele honderden tot duizenden base-paren. We kunnen daarom bijvoorbeeld een transitiematrix schatten als volgt:\n",
    "\n",
    "| Transities        | CGI (`+`)     | non-CGI (`-`) |\n",
    "| :---------------: | :-----------: | :-----------: |\n",
    "| **CGI** (`+`)     |    0.990      |    0.010      |\n",
    "| **non-CGI** (`-`) |    0.001      |    0.999      |\n",
    "\n",
    "Definieer een Hidden Markov Model op basis van bovenstaande gegevens en gebruik dit om de sequentie in het meegeleverde bestand `Casus_HiddenMarkovModel.fasta` te analyseren. Kies zelf geschikte startwaarschijnlijkheden. Op welke plekken vind je CpG-eilandjes? Wat is het GC-gehalte van alle CGI regios tezamen, en wat is het GC-gehalte van alle non-CGI regios?\n",
    "\n",
    "Tenslotte, vergelijk je eigen resultaten met die van een van onderstaande online tools:\n",
    "\n",
    "* https://www.bioinformatics.org/sms/cpg_island.html\n",
    "\n",
    "* https://groups.molbiosci.northwestern.edu/matouschek/links/sms2/cpg_islands.html\n",
    "\n",
    "* https://www.genscript.com/sms2/cpg_islands.html\n",
    "\n",
    "Deze maken geen gebruik van Hidden Markov Modellen, maar gebruiken een sliding-window techniek. Kun je iets zeggen over de mate waarin je eigen resultaten overeenkomen met die van dit tool? Kun je speculeren wat een reden kan zijn voor de verschillen?"
   ],
   "id": "2e2420f63400f5ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# UITWERKING",
   "id": "54db8aa8cfe8a782"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "&copy; 2025 - Dave R.M. Langers <d.r.m.langers@pl.hanze.nl>"
   ],
   "id": "3facc90468224642"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
